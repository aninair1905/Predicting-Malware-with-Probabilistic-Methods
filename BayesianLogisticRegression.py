import numpy as np
import pymc as pm
from sklearn.metrics import average_precision_score
from scipy.special import expit

class BayesianLogisticRegression:
    ''' 
    BayesianLogisticRegression for binary classification. Implemented using
    pymc.find_MAP, with Gaussian/Laplacian prior and Bernoulli likelihood.

    Initial Parameters:
     - penalty : str, can be 'L2' or 'L1
     - reg_strength : int, the strength of the regularization penalty
     - fit_intercept : bool, whether or not to add a bias before the sigmoid
     - random_state : None, int, or np.random.RandomState() instance, for 
        shuffling the training data
     - max_iter : int, number of training iterations for MAP estimation.
    
    Methods:
      - fit : fit a logistic regression to an X and y
      - predict_proba : predict class probability score for an X
      - predict : predict class labels for an X
      - score : score a model on an X and y (using area under precision recall curve)
    '''

    def __init__(self, penalty='L2', reg_strength=1.0, fit_intercept=True, 
                 random_state=None, max_iter=5000, verbose=True):
        
        self.penalty = str(penalty)
        self.reg_strength = int(reg_strength)
        self.fit_intercept = bool(fit_intercept)
        self.max_iter = int(max_iter)
        self.verbose = bool(verbose)

        if self.penalty == 'L2':
            self._prior = pm.Normal
        elif self.penalty == 'L1':
            self._prior = pm.Laplace
        else:
            raise ValueError(f'\'penalty\' must be \'L2\' or \'L1\'')

        if random_state is None:
            self.random_state = np.random.RandomState()
        elif isinstance(random_state, int):
            self.random_state = np.random.RandomState(random_state)
        elif isinstance(random_state, np.random.RandomState):
            self.random_state = random_state
        else:
            raise ValueError("\'random_state\' must be an integer, a RandomState instance, or None.")
    

    def fit(self, x_NF, y_N):
        ''' 
        fit a logistic regression to x_NF and y_N
        '''

        N, F = x_NF.shape
        assert y_N.shape[0] == N

        idxs = np.arange(N)
        self.random_state.shuffle(idxs)
        x_NF = x_NF[idxs, :]
        y_N = y_N[idxs]

        if self.fit_intercept:
            x_NF = np.hstack((x_NF, np.ones((N, 1))))

        with pm.Model() as self._pm_model:
            weights = self._prior('beta', 0, self.reg_strength, shape=x_NF.shape[1])
            
            linear = pm.math.dot(x_NF, weights)
            likelihood = pm.invlogit(linear)
            
            pm.Bernoulli('logit', p=likelihood, observed=y_N)
            
            # Find MAP estimate, getting the weights here
            self._weights = pm.find_MAP()

        return self
    
    def predict_proba(self, x_MF):
        ''' 
        predict class probabilities for x_MF
        '''
        print('here in proba!!!!')
        M, F = x_MF.shape
        print(M, F)
        if self.fit_intercept:
            x_MF = np.hstack((x_MF, np.ones((M, 1))))

        return expit(np.dot(x_MF, self._weights['beta']))
    
    def predict(self, x_MF):
        ''' 
        predict class labels for x_MF
        '''

        return self.predict_proba(x_MF) > 0.5
    
    def score(self, x_MF, y_M):
        ''' 
        score a model on x_MF and y_M
        uses area under precision recall curve
        '''
        print('here in score!!!!')
        y_pred_M = self.predict_proba(x_MF)
        return average_precision_score(y_M, y_pred_M, average='weighted')